---
layout: post
title: PCA降维与卷积升维
date: 2017-06-02
categories: blog
tags: [ML]
description: PCA用于降维时怎么理解，与卷积有何异同
---
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>

最近刚看了点*PCA*的应用，对于其能够实现降维感到很惊奇。只是给定一堆samples，给定每个sample的**属性值**，此外没有任何分类信息，就能够将属性的个数减少而不过多影响整体。
#### 它是如何办到的
PCA（Principal Component Analysis）用中文讲就是*主成分分析*。  
以鸢尾花数据集为例，给定150个samples，每个sample有4个属性，那么我们就有了一个150行4列的矩阵，这个矩阵储存了我们给出的全部信息。  
只需要对\\(A^{T}\cdot A\\)求特征值和特征向量就可以解决。  
$$A^{T}\cdot A\cdot u=\lambda \cdot u$$  
很明显，\\(A^{T}\cdot A\\)有4个特征值，将其从大到小排列分别为
\\(\lambda _{1},\lambda _{2},\lambda _{3},\lambda _{4}\\)，其对应的特征向量为\\(u_{1},u_{2},u_{3},u_{4}\\).
$$B= A\cdot \left ( u_{1},u_{2},u_{3},u_{4} \right )$$  
$$B_{i}= A\cdot u_{i}$$  
可以看出\\(u_{1}\\)是A对其最主要方向的映射，\\(B_{1}\\)是映射之后的属性值，需要降到几维，B就取前几列。

具体的公式推导与理解可以关注[协方差矩阵的路数](https://my.oschina.net/gujianhan/blog/225241) 和[投影方差的路数](http://blog.jobbole.com/109015/)，我这里不再赘述。

#### 怎么理解
- B的每一列，即每一个新的属性值都是A的每一个sample的4个属性值按照\\(u_{i}\\)进行映射得到的。
- PCA降维的理念是使降维之后各个sample仍是**容易区分**的，可以看做是按某种方式映射到低维后，其samples的方差最大。
- 这种**容易区分**的本质就是充分保留各个sample的**信息**。

#### 卷积用于降维
对于图像的处理，经常使用二维卷积，而卷积是通过设置卷积核的个数来调整通道数目，达到调整卷积输出的第三维大小的目的。其实质也是在调整特征的维数。  
对于图像的卷积，可以参看caffe作者贾扬清大神的知乎回答：[在Caffe中如何计算卷积？](https://www.zhihu.com/question/28385679)  
比如
#### 卷积可以用于升维，而PCA只能降维？
- 大家一定主要到了，PCA对维度的调整依赖于某个矩阵的特征向量，而其特征值的数目限制了它只能进行降维。  
- 对于二维卷积，当卷积核的数目小于输入通道数的时候，输出的通道数减小，最终flatten之后特征维数降低；相反，如果卷积核的数目大于输入通道数，最终的特征维数会升高。因此，卷积既能降维，又能升维。